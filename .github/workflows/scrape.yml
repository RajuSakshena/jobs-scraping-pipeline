name: Run All Job Scrapers

on:
  workflow_dispatch:
  schedule:
    - cron: "0 2 * * *"   # Daily at 2 AM UTC

concurrency:
  group: job-scraper
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    permissions:
      contents: write

    steps:

      # 1️⃣ Checkout Repository
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 2️⃣ Setup Python
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      # 3️⃣ Install Google Chrome
      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1

      # 4️⃣ Install Dependencies
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-action.txt

      # 5️⃣ Run Scraper
      - name: Run Scrapers
        run: |
          echo "Starting job scrapers..."
          python runner.py
          echo "Scraping completed successfully."

      # 6️⃣ Upload Output as Artifact
      - name: Upload Output Files
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: job-scraper-output
          path: output/

      # 7️⃣ Commit & Push Updated Excel
      - name: Commit & Push Combined.xlsx
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"

          git add output/Combined.xlsx

          if git diff --staged --quiet; then
            echo "No changes detected."
          else
            git commit -m "Auto update Combined.xlsx [$(date -u)]"
            git push
          fi
